---
title: "<br>Image Segmentation"
author: "Derek Wayne"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    df_print: paged
    highlight: tango
    css: style.css
    includes:
      before_body: header.html
      after_body: footer.html
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'index.html')) })
subtitle: Applications to Neuroimaging Analysis
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(eval.after = 'fig.cap')
```

# Introduction

The methods of [cluster analysis](https://derekwayne.github.io/clustering/) can be applied to the process of segmenting an image by assigning to each pixel a label indicating some form of shared characteristic such as boundaries or colours. The goal is to identify important regions of an image where each segment belongs to one particular surface, object, etc. There are applications in image processing/compression, object recognition, database searching, and edge detection for feature extraction.

The purpose of this project is to go over in detail the process of segmenting an image. The image involved will determine which frameworks are most effective in achieving a good segmentation of the image. We will look at the K-means algorithm, which performs well when objects in an image are well separated in a colour space; and we will look at a more advanced procedure for the task of segmenting soft tissues present in medical images of the brain.

# Simple Colour-Based Example

```{r include=FALSE}
library(imager)
library(ggplot2)
library(dplyr)
library(kableExtra)
library(knitr)
```
The [Imager](https://cran.r-project.org/web/packages/imager/index.html) package cotains some example images to work with. We will import the parrots file as it can highlight the ease with which algorithms can segment within a 3 dimensional color space (*RGB*).
```{r}
file <- system.file('extdata/parrots.png',package='imager')
parrots <- load.image(file)
parrots
```
The data is stored as a `cimg` class, which behaves identically as an array. For purposes of plotting with the ggplot2 package, which requires data be stored as a dataframe we convert the default cmig object. 
```{r}
parrots_df <- as.data.frame(parrots,wide="c") %>% # wide format with channels as columns
  mutate(rgb.val=rgb(c.1,c.2,c.3)) 
names <- c("x", "y", "R", "G", "B", "rgb.val")
colnames(parrots_df) <- names
```

```{r plotting theme, echo=FALSE}
# ggplot theme to be used
plotTheme <- function() {
  theme(
    panel.background = element_rect(
      size = 1,
      colour = "black",
      fill = "white"),
    axis.ticks = element_line(
      size = 2),
    panel.grid.major = element_line(
      colour = "gray80",
      linetype = "dotted"),
    panel.grid.minor = element_line(
      colour = "gray90",
      linetype = "dashed"),
    axis.title.x = element_text(
      size = rel(1.2)),
    axis.title.y = element_text(
      size = rel(1.2)),
    plot.title = element_text(
      size = 20,
      vjust = 1.5)
  )
}
```
```{r eval=FALSE, include=FALSE}
# Plot the image
ggplot(data = parrots_df, aes(x = x, y = y)) +
  geom_point(colour = rgb(parrots_df[c("R", "G", "B")])) +
  labs(title = "Original Image") +
  xlab("x") +
  ylab("y") +
  scale_y_reverse() +
  plotTheme() +
  coord_fixed()
ggsave("images/parrots_original.jpg")
```
```{r echo=FALSE, out.width = '50%'}
include_graphics("images/parrots_original.jpg")

# RGB Histograms
parrots_df2 <- as.data.frame(parrots) %>%
  mutate(channel=factor(cc,labels=c('R','G','B')))

ggplot(parrots_df2,aes(value,col=channel))+geom_histogram(bins=30)+facet_wrap(~ channel) + plotTheme() + theme(legend.position = "none")
```


The image has a wide colour palette that we hope will serve as the basis of our segmentation. Without using spacial information, each pixel has a corresponding 3-dimentional vector of color channels -- red, green, and blue. The K-means algorithm should perform well here since the colours help to differentiate the parrots from each other and the background (i.e. good separation).


# The K-Means++ Solution

The K-means method is a simple solution to the problem of finding clusters centers that minimize the variance within each cluster. Each cluster in our problem refers to a specific colour value. Consequently, a pixel is considered to be "like" another if they are near each other in the colour space. Euclidean distance will define the notion of "nearness". K-means requires that we specify the number of clusters a-priori. Determining the optimal number of clusters depends on the problem at hand. The goal of segmenting an image is only to find the clusters/colours that we deem most important in separating the objects. The salient colours in the parrots image are red, green, turquoise, yellow, white, and black. So we might choose the number of clusters to be around 6-8. Next, we need to choose a method of initalization for the pixel centers. The K-means++ algorithm is a seeding procedure for the centers which results in an improvement of the final error and a decrease in computation time. Intuitively, initial centers should be chosen such that they are not too close together. This idea is implemented in the function below.

```{r}
# rows are centers
centers <- function(x, k) {
  x <- as.matrix(x)
  center.mat <- matrix(0, nrow=k,ncol=ncol(x))
  center.init <- x[sample(nrow(x), size=1), ]
  center.mat[1, ] <- center.init
  for (i in 2:k) {
    e.dist <- sqrt(rowSums((x-center.init)^2)) # compute euclidean distance
    probs <- e.dist^2 / (max(e.dist)^2 + 1) # weighted probability
    center.new <- x[sample(nrow(x), size=1, prob=probs), ]
    
    center.mat[i, ] <- center.new
  }
  center.mat
}
```

Although this initialization process does require some computational effort, the K-means procedure should converge more quickly on average. Now we will use this in conjunction with R's built in `kmeans` function.

```{r}
kmpp <- function(x, k) {
  centers <- centers(x, k)
  kmeans(x, centers)
}
```


```{r}
cl <- kmpp(parrots_df[, c("R", "G", "B")], k=8) # 8 clusters
kColours <- rgb(cl$centers[cl$cluster, ])
cl2 <- kmpp(parrots_df[, c("R", "G", "B")], k=6) # 6 clusters
k2colours <- rgb(cl2$centers[cl2$cluster, ])
```

## Results

```{r eval=FALSE, fig.show="hold", include=FALSE, out.width="50%"}
ggplot(data = parrots_df, aes(x = x, y = y)) +
  geom_point(colour = k2colours) +
  labs(title = paste("k-Means Clustering of", 6, "Colours")) +
  xlab("x") +
  ylab("y") +
  scale_y_reverse() +
  plotTheme() +
  coord_fixed()
ggsave("images/parrots_6cl.jpg")

ggplot(data = parrots_df, aes(x = x, y = y)) +
  geom_point(colour = kColours) +
  labs(title = paste("k-Means Clustering of", 8, "Colours")) +
  xlab("x") +
  ylab("y") +
  scale_y_reverse() +
  plotTheme() +
  coord_fixed()
ggsave("images/parrots_8cl.jpg")
```
```{r echo=FALSE, out.width = "50%", fig.show="hold"}
include_graphics("images/parrots_6cl.jpg")
include_graphics("images/parrots_8cl.jpg")
```

# Application to Neuroimaging
## Segmentation of T1-weighted Brain MR Acquisitions

A magnetic resonance imaging (MRI) scan of the brain presents an important application of image-based segmentation. For example, an accurately segmented scan can assist in the diagnosis of brain disease and in the preparation of surgery. The three main tissue classes that are normally segmentated in a scan are white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF). Facilitating segmentation requires high contrasts between these tissue types. To generate improved tissue contrasts requires varying parameters of the pulse sequences responsible for causing the hydrogen atoms contained in the body to emit radio frequencies when subjected to a magnetic field. The contrasts achieved through MRI scans is an improvement over computed tomography. However, results still suffer from the following obstacles to segmentation

1. Electronic noise -- disturbance in the electrical signal
2. A bias field -- An unwanted artifact producing inhomogenous intensities of tissue regions
3. The partial volume effect -- overlap of tissue classes within a voxel

The paper [Segmentation of Brain MR Images Through a Hidden Markov Random Field Model and the Expectation-Maximization Algorith](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.200.3832&rep=rep1&type=pdf) by Yongyue Zhang et al. provides justification for a Hidden Markov Random Field (HMRF) model together with an Expectation Maximization (EM) method of iterative parameter updating, for a framework that effectively overcomes these difficulties in segmentation.

In this project we adopt this framework to segment an MRI scan obtained from the *mritc* package. The success of this approach offers a means for automatic brain MR image segmentation.

## NIfTI data format
```{r echo=FALSE, out.width = "20%", out.extra='style="float:right; padding:10px"'}
include_graphics("images/voxels.png")
```
The Neuroimaging Informatics Technology Initiative (NIfTI) format is an improvement on the ANALYZE format, retaining a header/image combination of data but also allowing for storage of auxillary information inside the file. The `readMRI` function from the *mritc* package can be used to obtain a three dimensional array with the appropriate image dimensions. The three dimensional analogue to a pixel is called a voxel -- a unit within a three dimensional grid (as shown on the right); representing a signal intensity (ranging from 0 to 250).

Source for figure to the right: https://commons.wikimedia.org/wiki/File:Voxels.svg

```{r include=FALSE}
library(mritc)
library(tkrplot)
```
```{r}
# Read in NIfTI data
T1 <- readMRI(system.file("extdata/t1.rawb.gz", package="mritc"),
              c(91, 109, 91), format="rawb.gz")
# Read in the mask for non-brain matter
mask <- readMRI(system.file("extdata/mask.rawb.gz", package="mritc"),
                c(91, 109, 91), format="rawb.gz")
```

```{r include=FALSE}
slice1 <- T1[,,45] # axial
slice2 <- T1[45,,] # coronal
slice3 <- T1[,50,] # saggital
```


```{r, echo = FALSE, fig.show="hold", out.width="33%"}
slice_df1 <- as.cimg(slice1) %>% as.data.frame()
slice_df2 <- as.cimg(slice2) %>% as.data.frame()
slice_df3 <- as.cimg(slice3) %>% as.data.frame()


p1 <- ggplot(slice_df1,aes(x,y))+geom_raster(aes(fill=value)) +
  labs(title = "Axial/Transverse View") +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_fill_gradient(low="black",high="white") +
  coord_fixed() +
  plotTheme() +
  theme(legend.position = "none")
p1

p2 <- ggplot(slice_df2,aes(x,y))+geom_raster(aes(fill=value)) +
  labs(title = "Saggital View") +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_fill_gradient(low="black",high="white") +
  coord_fixed() +
  plotTheme() +
  theme(legend.position = "none")
p2

p3 <- ggplot(slice_df3,aes(x,y))+geom_raster(aes(fill=value)) +
  labs(title = "Coronal View") +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_fill_gradient(low="black",high="white") +
  coord_fixed() +
  plotTheme() +
  theme(legend.position = "none")
p3
```

## Constructing a Markov Random Field

To make inferences on the data we consider an three dimensional image graph denoted $\mathcal{G} = (\mathcal{V}, \mathcal{E})$, where $\mathcal{V}$ is the set of nodes corresponding to $N = 91 \times 109 \times 91$ voxels making up the three dimensional image, and $\mathcal{E}$ corresponds to undirected edges. As mentioned earlier, the set of hidden classes attributable to each node is $\mathcal{S} =\{WM, GM, CSF \}$, which are to be estimated from the pixel intensities (observations). Below is a density plots of the signal intensities taken from three different levels of depth into the saggital plane.

```{r, echo = FALSE, fig.show="hold", out.width="50%"}
t1 <- T1
t1[mask==0] <- NA #remove non brain matter using mask

slice1 <- t1[50,,] %>%
  as.cimg() %>%
  as.data.frame()

ggplot(slice1,aes(x,y))+geom_raster(aes(fill=value)) +
  labs(title = "Saggital View: with mask") +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_fill_gradient(low="black",high="white") +
  coord_fixed() +
  plotTheme() +
  theme(legend.position = "none")

slice2 <- t1[30,,] %>%
  as.cimg() %>%
  as.data.frame()
slice3 <- t1[70,,] %>%
  as.cimg() %>%
  as.data.frame()

library(reshape2) # need to reshape data for overlaid density plots
df <- data.frame("x.50"=slice1$value, "x.30"=slice2$value, "x.70"=slice3$value)
df <- suppressMessages(melt(df, na.rm = TRUE))

# overlaid density plots
ggplot(df,aes(x=value, fill=variable)) + geom_density(alpha=0.25, na.rm = TRUE) + plotTheme() +
  labs(title = "Density plot of Signal Intensities") +
  scale_fill_discrete(name = "Levels of Depth", labels = c("50", "30", "70"))
  
```

Heuristically, we assume the three modes present in the above plot correspond to our three classes. CSF often attains lower values, GM tends to land somehwere in the middle, and WM most often have the highest intensities. From this information a mixture of three Gaussian distributions seems like an appropriate model. The limitation of this approach rests with the fact that there is no spacial information accounted for. 

```{r echo=FALSE, out.width = "40%", out.extra='style="float:right; padding:10px"'}
include_graphics("images/voxel_nbhd.png")
```

To incorperate the greater likelihood of neighbouring voxels to share a class label, an edge $(i,j) \in \mathcal{E}$ must be accompanied by a bias that encodes such a tendency between voxels. A Markov model accounts only for the dependencies between voxels sharing a common edge. That is, for voxel $i$ define the set of its neighbours to be $\mathcal{N_i} = \{j: (i,j) \in \mathcal{E} \}$.

Source for figure to the right:  [Photogrammetric Engineering & Remote Sensing, Volume 84, Number 6](https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00015?crawler=true&mimetype=application/pdf#)

The sequence of voxel labels, denoted $\{X_1, \dots, X_{N}\}$ is said to be a Markov Random Field (MRF) on the state space $\mathcal{S}$ with respect to $\mathcal{N}$, if and only if it has the following properties:

1. $P(\mathbf{x}) > 0$, for all $\mathbf{x}$
2. The $X_i$'s are dependent only on their neighboring sites $\mathcal{N_i}$ for all $i$

[The Hammersley-Clifford theorem](https://en.wikipedia.org/wiki/Hammersley%E2%80%93Clifford_theorem) states that a MRF with the properties listed above is equivalently a Gibbs random field -- that is, we may express the MRF as a Gibbs distribution:
$$
P(\mathbf{x}) = \frac{1}{Z}exp\bigg\{-\sum_{c\in\mathcal{C}}\Psi_c(\mathbf{x}) \bigg\}
$$
where $Z$ represents the normalizing constant (or partition function) to make the distribution sum to unity, and $E(\mathbf{x}) = \sum_{c \in \mathcal{C}}\Psi_c(\mathbf{x})$ is the cost function for the learning stage. Here $\mathcal{C}$ denotes the collection of cliques in the graph $\mathcal{G}$. A clique $c$ is a subgraph of $\mathcal{G}$ that is fully connected -- meaning each distinct pair of voxel sites ($i, j \, : i\neq j$) are neighbouring ($i \in \mathcal{N_j} \wedge j \in \mathcal{N_i}$).

The value of the clique potential $\Psi_c(\mathbf{x})$ should decrease $E(\mathbf{x})$ when two neighbouring voxels have similar intensities, and thus increase the joint probability $P(\mathbf{x})$.

## A Special Case of a Hidden Markov Model

Without the spacial property incorperated by the definition of the neighbourhood system $\{\mathcal{N_i}, i = 1, 2, \dots, N\}$ the sequence of voxel labels can be characterized by a first order Markov chain whose state space is hidden and cannot be observed. This implies a proper hidden Markov model (HMM). However, to model the spatial property of a two or three dimensional image, we assume the generating stochastic process is the more general Markov random field; as in the previous section.

In addition to the hidden random field $\{X_i, i = 1, 2, \dots, N \}$ we must model the *observable random field* $Y = \{Y_i, i = 1,2, \dots, N \}$ having the finite state space $\mathcal{D} = \{0,1, \dots, 250\}$ representing the voxel intensities. We call $Y$ the *emitted random field*, where $Y_i \perp Y_j  \, | \, \mathbf{x}$ for $i \neq j$.

Given a sequence of class labels $\{x_i \}$ the likelihood of each observed intensity value has the conditional probability distribution $p(y_i \, | \, x_i, \theta_s)$, with $\theta_s$ dependent on the states $s \in \mathcal{S}$. Accounting for the local dependencies within neighbourhoods $\mathcal{N}_i$ from the MRF, each pair $(X_i, Y_i)$ has the joint probability

$$
P(y_i , x_i \, | \, x_{\mathcal{N}_i}) = P(y_i \, | x_i)P(x_i \, | \, x_{\mathcal{N}_i})
$$
by applying Bayes' rule (Yongyue Zhang et al., eq (8)). Thus, by marginalizing over the states $s \in \mathcal{S}$ obtain
$$
\begin{aligned}
p(y_i \, | \, x_{\mathcal{N}_i}, \, \theta) &= \sum_{s \in \mathcal{S}}p(y_i, s \, | \, x_{\mathcal{N}_i}, \theta) \\
&= \sum_{s \in \mathcal{S}} f(y_i; \theta_s)p(s \, | x_{\mathcal{N}_i})
\end{aligned}
$$
where $\theta = \{\theta_s, s \in \mathcal{S} \}$ (Yongyue Zhang et al., eq (9)). Where Zhang (2001) defines this to be the *hidden Markov random field* model. We assume that the intensity values are independent and normally distributed with parameters $\theta_s = (\mu_s, \sigma_s)^T$ depending on the tissue class. That is,

$$
p(\mathbf{y} \, | \, \mathbf{x}_{\mathcal{N}}, \, \theta) = \prod_{i=1}^N\sum_{s\in \mathcal{S}}\mathcal{N}(y_i \, ; \, \mu_s, \sigma_s)p(s \, |\, x_{\mathcal{N}_i})
$$
It can be seen that if we had assumed that the tissue types were independent of each other, the equation above reduces to the finite normal mixture model -- thus highlighting the key difference between the HMRF model and the FM model.

## Tissue Classification using Iterated Conditional Modes

Class labels $\mathbf{x}$ will be estimated via the  *maximum a-posteriori* criterion. That is,
$$
\begin{aligned}
\hat{\mathbf{x}} &= \text{arg}\max_{\mathbf{x}} \{P(\mathbf{y} \, | \, \mathbf{x})P(\mathbf{x}) \} \\
&= \text{arg}\max_{\mathbf{x}} \bigg\{\prod_{i=1}^N\mathcal{N}(y_i \, ; \, \mu_s, \sigma_s) \, \big[e^{-E(\mathbf{x})} \big] \bigg\} \\
&= \text{arg}\min_{\mathbf{x}}\bigg\{\sum_{i=1}^N\bigg[\frac{(y_i-\mu_{x_i})^2}{2\sigma^2_{x_i}} + log \, \sigma_{x_i} \bigg] +  \sum_{c\in\mathcal{C}}\Psi_c(\mathbf{x})\bigg\}
\end{aligned}
$$
Multiple authors have suggested using the *iterated condition modes* (ICM) algorithm, which takes turns maximizing the probability of each parameter conditioned on the others. It has the advantage of fast convergence (only requiring a few iterations), but can get trapped at local maxima (or minima in this case).

### Incorperating Partial Volume Effect

When considering the MRF model $p(\mathbf{x})$ we may decide to include the realistic assumption that not all voxels are homogenous. It is possible that multiple tissue classes occupy the same voxel; this issue is known as the *partial volume effect*. Suppose we introduce extra classes CSF/GM with $\mu_{CSF/GM}=\frac{1}{2}(\mu_{CSF} + \mu_{GM})$, $\sigma^2_{CSF/GM}=\frac{1}{2}(\sigma^2_{CSF} + \sigma^2_{GM})$ and GM/WM with parameters defined similairly. The partial volume HMRF-EM model can be used with `mritc.pvhmrfem(...)` from the *mritc* package.

## Segmentation with Bias Field Correction

An MRI machine generates a magnetic field in order to cause hydrogen atoms within the brain to emit a radio frequency. These desired frequencies can be corrupted by another low frequency artifact known as a *bias field*. It is generally considered to be noise caused by equipment -- thus scans produced by older machines are more suspect. An automatic correction is available through `mritc.hmrf` with `bias = TRUE`.

```{r echo=FALSE, out.width = "30%", out.extra='style="float:right; padding:10px"'}
include_graphics("images/bias_field.png")
```

1. **Expectation Step**
  + Estimate the bias field component <br> \vspace{5pt} $\quad B^{(k)} = \text{arg}\max_{B} \,\,p(B \, | \, \mathbf{y}, \mathbf{x}^{(k-1)}, \theta^{(k-1)})$

  + Estimate class labels <br> $\quad \mathbf{x}^{(k)} = \text{arg}\max_{\mathbf{x}} \,\, P(\mathbf{x} \, | \, \mathbf{y}, B^{(k)}, \theta^{(k)})$

2. **Maximization Step**
  + Obtain updates for model parameters <br> $\quad \theta^{(k+1)} = \text{arg}\max_{\mathbf{\theta}} \,\, P\big(\mathbf{y} \, | \, \theta, \mathbf{x^{(k)}}, B^{(k)} \big)$


Source for figure on the right: [A New Multistage Medical Segmentation Method Based on Superpixel and Fuzzy Clustering](https://www.researchgate.net/figure/The-illustration-of-bias-field-in-MRI-image_fig12_261738082)
## Experiments

In the following implementations we adopt the pure voxel assumption. That is, we do not consider the partial volume effect. This is because we only have data containing the true labels for three classes, and therefore cannot calculate the misclassification error assuming the extra two combination classes discussed earlier.

### Initializing Parameters with Otsu's Method

Both the EM (for model parameters) and ICM (for label estiamtion) algorithms are not guaranteed to converge globally. Thus, the choice of initial conditions can determine the success of the segmentation.

Otsu's method can be used to determine estimates of the means and variances for each class from the grayscale histogram of an image. The algorithm seeks to find thresholds which minimize the intraclass variances.
```{r}
y <- T1[mask==1]
initial <- initOtsu(y, 2)
prop <- initial$prop
mu <- initial$mu
sigma <- initial$sigma
```

```{r include=FALSE}
library(gridExtra)
library(gtable)
library(grid)
```

```{r echo = FALSE, fig.align="center", out.width="70%"}
summarytable <- as.data.frame(initial) %>%
  round(2)

rownames(summarytable) <- c("CSF", "GM", "WM")
# Set theme to allow for plotmath expressions
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)), padding = unit(c(0.5,0.5), "cm"))
tbl <- tableGrob(summarytable, theme=tt)
tbl <- gtable_add_grob(tbl,
        grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
        t = 2, b = nrow(tbl), l = 1, r = ncol(tbl))
tbl <- gtable_add_grob(tbl,
        grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
        t = 1, l = 1, r = ncol(tbl))


d <- rnormmix(10000, prop=prop, mu=mu, sigma=sigma) %>%
  as.data.frame()
plt <- ggplot(data.frame("y"=y), aes(x=y)) + geom_histogram(aes(y=..density..), bins=45, fill="darkgrey", colour="black") +
  geom_density(aes(x=y), d, size = 0.70, fill = "steelblue", alpha = 0.5) + plotTheme() +
  labs(title="Otsu Initializations", x="Intensity") +
  theme(plot.margin = unit(c(0.4, 0.5, -2.4, 0.1), "cm"))


grid.arrange(plt, tbl,
             ncol=2,
             as.table=TRUE,
             heights = c(2.8,1),
             widths = c(2.8,1.5))
```

### Model Fitting

```{r}
mrispatial <- makeMRIspatial(mask, nnei = 6, sub = FALSE)
```

```{r}
tc.hmrfem <- mritc.hmrfem(y, mrispatial$neighbors, mrispatial$blocks, mu=mu, sigma=sigma, verbose = FALSE)
```

```{r}
tc.em <- mritc.em(y, prop=prop, mu=mu, sigma=sigma, verbose = FALSE)
```


```{r}
csf <- readMRI(system.file("extdata/csf.rawb.gz", package = "mritc"),
 c(91, 109, 91), format = "rawb.gz")
gm <- readMRI(system.file("extdata/gm.rawb.gz", package = "mritc"),
 c(91, 109, 91), format = "rawb.gz")
wm <- readMRI(system.file("extdata/wm.rawb.gz", package = "mritc"),
 c(91, 109, 91), format = "rawb.gz")

truth <- cbind(csf[mask == 1], gm[mask == 1], wm[mask == 1])
truth <- truth/255
```

```{r fig.show="hold", out.width="50%"}
res.hmrf <- measureMRI(T1[mask == 1], truth, tc.hmrfem$prob)
res.em <- measureMRI(T1[mask == 1], truth, tc.em$prob)
```

```{r echo=FALSE, fig.show="hold", out.width="50%"}
actual <- c(rep("CSF",3), rep("GM",3), rep("WM",3))
predicted <- c(rep(c("CSF", "GM", "WM"), 3))
value.hmrf <- as.vector(t(res.hmrf$conTable)) # obtain values from table
value.hmrf <- round(value.hmrf, 2)
ctable.hmrf <- data.frame(actual, predicted, value.hmrf)

value.em <- as.vector(t(res.em$conTable)) # obtain values from table
value.em <- round(value.em, 2)
ctable.em <- data.frame(actual, predicted, value.em)


ggplot(data =  ctable.hmrf, mapping = aes(x = predicted, y = actual)) +
  geom_tile(aes(fill = value.hmrf), colour = "white") +
  geom_text(aes(label =  value.hmrf), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  plotTheme() + theme(legend.position = "none") +
  labs(title = "HMRF-EM")

ggplot(data =  ctable.em, mapping = aes(x = predicted, y = actual)) +
  geom_tile(aes(fill = value.em), colour = "white") +
  geom_text(aes(label =  value.em), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  plotTheme() + theme(legend.position = "none") +
  labs(title = "EM")
```


[Interactive Result Plots](https://derekwayne.shinyapps.io/brain_mri_segmentation/)

## Conclusion


```{r echo = FALSE}
tc.icm <- mritc(T1, mask, method = "ICM")
t1 <- T1
t1[mask == 1] <- 0
icm.class <- max.col(tc.icm$prob)
tc.icm$mask[tc.icm$mask == 1] <- icm.class
```

```{r echo = FALSE}
plt_brain <- function(plane = "saggital", k, mask) {
  # mask is a three dimensional array -- from mritc object
  
  if (plane == "saggital") mask.img <- as.cimg(tc.icm$mask[k,,])
  else if (plane == "coronal") mask.img <- as.cimg(tc.icm$mask[,k,])
  else mask.img <- as.cimg(tc.icm$mask[,,k])
  
  mask_df <- as.data.frame(mask.img)
  
ggplot(mask_df,aes(x,y))+geom_raster(aes(fill=value)) +
  labs(title = "Axial/Transverse View") +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_fill_gradient(low="black",high="white") +
  coord_fixed() +
  plotTheme() +
  theme(legend.position = "none")
}
```

### A work in progress